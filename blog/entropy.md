# Entropy from Stirling's Approximation

When I think about entropy I tend to get confused. You can arrive at the definition of entropy from a few different directions,namely from thermodynamics,statistical mechanics,or information theory.

At its heart,entropy is really combinatorics: it's a measure of the number of ways you can arrange a system while maintaining some macroscopic property. For example,if you have a box of gas,the entropy of the gas is a measure of the number of ways you can arrange the gas molecules while maintaining the same pressure,volume,and temperature. 
This is why entropy is an extensive variable -- the larger the system the more accesible arrangements there are,so the higher the entropy.

